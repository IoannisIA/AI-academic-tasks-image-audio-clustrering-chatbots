import numpy as np
import pandas as pd
import pandas_profiling as pp
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline
from sklearn import datasets
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
train = pd.read_csv("../input/train.csv")
train.head(5)

# https://www.kaggle.com/shubhendra7/digit-recognizer-pca-kmeans

#pp.ProfileReport(train)

# Separating out the features
x = train.iloc[:,1:].values

# Separating out the label
y = train.loc[:,['label']].values

# Standardizing the features
x = StandardScaler().fit_transform(x)


pca = PCA(n_components=2)
principalComponents = pca.fit_transform(x)
principalDf2 = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])

finalDf = pd.concat([principalDf2, train[['label']]], axis = 1)
finalDf.head(5)

df_list = [x[1] for x in finalDf.groupby(('label'), sort=True)]

for i in range(1, len(df_list)):
    df_list[i] = df_list[i].reset_index()
    df_list[i] = df_list[i].drop(['index'], axis=1)

for i in range(0, 10):
    df_list[i].plot(x="principal component 1", y="principal component 2", kind="scatter", label='%s data' % i)


x = train.iloc[:,1:].values

# Separating out the target
y = train.loc[:,['label']].values

# Standardizing the features
x = StandardScaler().fit_transform(x)


pca = PCA(n_components=30)
principalComponents = pca.fit_transform(x)
principalDf30 = pd.DataFrame(data = principalComponents)

DIGITS_PCA_30 = pd.concat([principalDf30, train[['label']]], axis = 1)
DIGITS_PCA_30.head(5)

# Subsetting the data into clusters for 0-9, labelled data
df_list_30_label = [x[1] for x in DIGITS_PCA_30.groupby(('label'), sort=True)]

##Creating a list of dataframes and then utilizing single element(dataset) to sample 10 values

for i in range(0, len(df_list_30_label)):
    df_list_30_label[i] = df_list_30_label[i].reset_index()
    df_list_30_label[i] = df_list_30_label[i].drop(['index'], axis=1)

##Creating empty lists so that elements can be appended later
center_list = []
km_iterlist = []
purity = []
class_label = []
for i in range(0, 10):
    class_label.append(i)
    # print(class_label)
    center = df_list_30_label[i].sample(n=10, replace=True)
    center_list.append(center)
    center_list[i] = center_list[i].drop(['label'], axis=1)

    ###initialize the same 10 values as the "init" parameter in Kmeans

    # print(center_list[i])
    ##The stopping criteria for each cluster convergence is dependent on the iterations which are 300 by default
    km = KMeans(n_clusters=10, init=center_list[i], n_init=1).fit(principalDf30)
    ykmeans = km.predict(principalDf30)
    df_temp = pd.DataFrame(y, ykmeans, columns=["True"]).reset_index()
    df_temp.head(5)
    majority_count = 0
    for i in df_temp["index"].unique():
        df_inner = df_temp[df_temp["index"] == i]
        count_true_values = df_inner["True"].value_counts()
        # print(count_true_values)
        majority_count += count_true_values.iloc[0]
    majority_purity = majority_count / 42000
    purity.append(majority_purity)
    # print(purity)

    km_iterlist.append(km.n_iter_)
    # print(km_iterlist)

Purity_ = pd.DataFrame()
Purity_["Class_label"] = class_label
Purity_["No.of Iteration"] = km_iterlist
Purity_["Purity factor"] = purity

Purity_

###Initialize the 10 cluster centers â€“ one from each class
### The only difference in the code is the init parameter in the Kmeans algorithm , wherein the sample of 1 values is taken from the each dataset

# Subsetting the data into clusters for 0-9, labelled data
df_list_30 = [x[1] for x in DIGITS_PCA_30.groupby(('label'), sort=True)]

for i in range(0, len(df_list_30)):
    df_list_30[i] = df_list_30[i].reset_index()
    df_list_30[i] = df_list_30[i].drop(['index'], axis=1)

center_list = []
km_iterlist = []

for i in range(0, 10):
    center = df_list_30[i].sample(n=1, replace=True)
    center_list.append(center)
    center_list[i] = center_list[i].drop(['label'], axis=1)

clist = pd.concat(center_list)
# print(cl)
### The only difference in the code is the init parameter in the Kmeans algorithm , wherein the sample of 1 values is taken from the each dataset

km = KMeans(n_clusters=10, init=clist, n_init=1).fit(principalDf30)

y_kmeans = km.predict(principalDf30)
df_temp = pd.DataFrame(y, y_kmeans, columns=["True"]).reset_index()
df_temp.head(5)
majority_count_class = 0
for i in df_temp["index"].unique():
    df_inner = df_temp[df_temp["index"] == i]
    count_true_values = df_inner["True"].value_counts()
    print(count_true_values)
    majority_count_class += count_true_values.iloc[0]

majority_label = majority_count_class / 42000
print(majority_label)

iteration = km.n_iter_
print(iteration)

Purity_.loc[10] = np.array(["All", iteration, majority_label])

##Printing the table with the purity and iteration values for different initialization scenarios
Purity_

###6b

center_list = []
kmiterlist = []
kmeans_list = [5, 10, 15, 20, 25]

purity_list = []
for i in range(0, len(kmeans_list)):

    # print(center_list[i])
    km = KMeans(n_clusters=kmeans_list[i], init="random", n_init=1).fit(principalDf30)

    # print(km.n_iter_)
    # kmiterlist.append(km.n_iter_)

    y_kmeans = km.predict(principalDf30)
    df_temp = pd.DataFrame(y, y_kmeans, columns=["True"]).reset_index()
    df_temp.head(5)

    majority_count_value = 0

    for i in df_temp["index"].unique():
        df_inner = df_temp[df_temp["index"] == i]
        count_true_val = df_inner["True"].value_counts()
        # print(count_true_val)
        majority_count_value += count_true_val.iloc[0]

    majority_purity_label = majority_count_value / 42000
    # print(majority_purity_label)
    purity_list.append(majority_purity_label)

sns.scatterplot(kmeans_list, purity_list)
plt.title("K-values vs Purity")